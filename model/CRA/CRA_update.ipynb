{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle as pickle\n",
    "import numpy as np\n",
    "base_path=\"../data/data_m3/\"\n",
    "with open(base_path+'binary_train_codes_x.pkl', 'rb') as f0:\n",
    "  binary_train_codes_x = pickle.load(f0)\n",
    "\n",
    "with open(base_path+'binary_test_codes_x.pkl', 'rb') as f1:\n",
    "  binary_test_codes_x = pickle.load(f1)\n",
    "\n",
    "train_codes_y = np.load(base_path+'train_codes_y.npy')\n",
    "train_visit_lens = np.load(base_path+'train_visit_lens.npy')\n",
    "\n",
    "test_codes_y = np.load(base_path+'test_codes_y.npy')\n",
    "test_visit_lens = np.load(base_path+'test_visit_lens.npy')\n",
    "train_pids = np.load(base_path+'train_pids.npy')\n",
    "\n",
    "test_pids = np.load(base_path+'test_pids.npy')\n",
    "with open(base_path+'patient_time_duration_encoded.pkl', 'rb') as f80:\n",
    "  patient_time_duration_encoded = pickle.load(f80)"
   ],
   "id": "3d9d8f39f6be2fdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open(base_path+\"code_map.pkl\", \"rb\") as f:\n",
    "    code_map = pickle.load(f)\n",
    "\n",
    "inv_code_map = {v-1: k for k, v in code_map.items()}\n",
    "print(code_map)\n",
    "def fun1(idx):\n",
    "    result=[]\n",
    "    for id in idx:\n",
    "        result.append(inv_code_map[id])\n",
    "    return result"
   ],
   "id": "5a450eea3271e522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(base_path+'diagnosis_icd9_ontology.csv')\n",
    "code2name = dict(zip(df['code'], df['name']))"
   ],
   "id": "ccedf8d9383205e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_diag_str(diag_list):\n",
    "    temp_str_list=[]\n",
    "    for diag in diag_list:\n",
    "        temp_str_list.append(f'\"{code2name[diag]}\"')\n",
    "    temp_str=', '.join(temp_str_list)\n",
    "    return temp_str"
   ],
   "id": "874574f4defff2d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def number_to_capitalized_ordinal(n):\n",
    "    p = inflect.engine()\n",
    "    return p.ordinal(p.number_to_words(n)).capitalize()\n",
    "\n",
    "# 示例\n",
    "print(number_to_capitalized_ordinal(1)) \n",
    "print(number_to_capitalized_ordinal(42)) \n"
   ],
   "id": "7c5cae6f526b3567",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "with open(\"pred_m3/m3_col_r1_result.pkl\", \"rb\") as f:\n",
    "    last_result = pickle.load(f)\n",
    "len(last_result)"
   ],
   "id": "a6d3539bc69461bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "with open(\"cra_result_m3/m3_cra_r1.json\", \"r\",encoding=\"utf-8\") as f:\n",
    "    hist_llm_result=json.load(f)"
   ],
   "id": "332b1504162abb0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(base_path + 'diagnosis_icd9_ontology.csv')\n",
    "code2name = dict(zip(df['code'], df['name']))\n",
    "import pickle\n",
    "\n",
    "with open(base_path + \"code_map.pkl\", \"rb\") as f:\n",
    "    code_map = pickle.load(f)\n",
    "\n",
    "inv_code_map = {v - 1: k for k, v in code_map.items()}\n",
    "\n",
    "print(code_map['414.01'] - 1)\n",
    "code_map_idx = list(code_map.keys())\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(base_path + 'diagnosis_icd9_ontology.csv')\n",
    "df['code'] = df['code'].astype(str).str.strip()\n",
    "df['name'] = df['name'].astype(str).str.strip()\n",
    "df_f = df[df['code'].isin(code_map_idx)].copy()\n",
    "name2code = dict(zip(df_f['name'].str.lower(), df_f['code']))\n",
    "\n",
    "\n",
    "def extract_diagnoses_final(pred_str: str, name_to_code: dict):\n",
    "    diagnoses_with_pos = []\n",
    "    pred_str_lower = pred_str.lower()\n",
    "\n",
    "    for name in name_to_code:\n",
    "        name_lower = name.lower()\n",
    "        index = pred_str_lower.find(name_lower)\n",
    "        if index != -1:\n",
    "            diagnoses_with_pos.append((index, name_lower))\n",
    "    diagnoses_with_pos.sort(key=lambda x: x[0])\n",
    "\n",
    "    return [name for _, name in diagnoses_with_pos]\n",
    "\n",
    "\n",
    "def remove_duplicates_keep_order(lst):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_diag_str(diag_list):\n",
    "    temp_str_list = []\n",
    "    for diag in diag_list:\n",
    "        temp_str_list.append(f'\"{code2name[diag]}\"')\n",
    "    temp_str = ', '.join(temp_str_list)\n",
    "    return temp_str\n",
    "\n",
    "\n",
    "import inflect\n",
    "\n",
    "\n",
    "def number_to_capitalized_ordinal(n):\n",
    "    p = inflect.engine()\n",
    "    return p.ordinal(p.number_to_words(n)).capitalize()\n",
    "\n",
    "\n"
   ],
   "id": "41bcfb536ea887cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results=[]\n",
    "ode_idx=0\n",
    "top_k=50\n",
    "for i in range(len(test_codes_y)):\n",
    "    if test_visit_lens[i]<2:\n",
    "        continue\n",
    "    pids=test_pids[i]\n",
    "    hist_diag=binary_test_codes_x[i]\n",
    "    target_diag=test_codes_y[i]\n",
    "    hist_diag_code=[]\n",
    "    all_hist_diag_code=[]\n",
    "    # ode_pred=data[ode_idx]\n",
    "    # \n",
    "    # ode_idx+=1\n",
    "    # ode_pred = np.argsort(-ode_pred, axis=-1)\n",
    "    last=last_result[ode_idx]\n",
    "    pred_str=hist_llm_result[ode_idx]['pred'].lower()\n",
    "    ode_idx+=1\n",
    "    for v in hist_diag:\n",
    "        hist_diag_code.append(fun1(np.where(v == 1)[0]))\n",
    "        all_hist_diag_code.extend(hist_diag_code[-1])\n",
    "    # hist_diag_code.append(fun1(np.where(target_diag == 1)[0]))\n",
    "    all_hist_diag_code=list(set(all_hist_diag_code))\n",
    "    \n",
    "    instruction='''\n",
    "You are an experienced medical diagnosis expert specializing in longitudinal disease progression and comorbidity reasoning.\n",
    "\n",
    "Your task is to UPDATE the diagnosis list for the patient’s final visit by carefully comparing:\n",
    "(1) the Previous Agent Output (CRA),\n",
    "and\n",
    "(2) the Collaborative Multi-Expert Consensus (COL),\n",
    "together with the patient’s longitudinal diagnosis history.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    duration=patient_time_duration_encoded[pids]\n",
    "    \n",
    "    input_=\"\"\n",
    "    for idx,code_list in enumerate(hist_diag_code):\n",
    "        if idx==0:\n",
    "            cur_duration=0\n",
    "            temp=number_to_capitalized_ordinal(idx+1)+f\" Visit:\"\n",
    "        else:\n",
    "            cur_duration+=duration[idx]\n",
    "            temp=number_to_capitalized_ordinal(idx+1)+f\" Visit: ({cur_duration} days later):\"\n",
    "\n",
    "        temp+=f\"\\n- Diagnoses：\"+\"{\"+get_diag_str(code_list)+\"}\"\n",
    "        input_+=temp+\"\\n\\n\"\n",
    "    temp=f\"Final Visit ({sum(duration)} days later):\\n\\n\"\n",
    "\n",
    "    pred_str=pred_str.replace(\"*\",\"\")\n",
    "    diagnoses=extract_diagnoses_final(pred_str.lower(),name2code)\n",
    "\n",
    "\n",
    "    codes = []\n",
    "    for name in diagnoses:\n",
    "        code = name2code.get(name)\n",
    "        if code is not None:\n",
    "            codes.append(code)\n",
    "    \n",
    "    pred_list=codes\n",
    "    pred_list = remove_duplicates_keep_order(pred_list)\n",
    "    temp_pred=[code_map[code]-1 for code in pred_list]\n",
    "    temp+='''Previous Agent Output: \\n{'''+get_diag_str(fun1(temp_pred))+\"}\"\n",
    "    temp+='''\\n\\nCollaborative Multi-Expert Consensus: \\n{'''+get_diag_str(fun1(last))+\"}\"\n",
    "    temp+='''   \n",
    "\\n\\nYour task:\n",
    "- Update the final-visit diagnosis list by integrating the longitudinal disease trajectory, recurrence patterns, and complication chains.\n",
    "- When revising the list, prioritize progressive, persistent, or downstream secondary conditions supported by the longitudinal history, and systematically down-rank transient, reversible, or treatment-related acute events unlikely to persist.\n",
    "- Carefully compare CRA and COL to refine the output: retain clinically plausible and persistent conditions agreed upon or supported by the trajectory, remove implausible or nonpersistent items, and supplement missing chronic/progressive diseases highlighted by COL when they are justified by longitudinal evidence.\n",
    "\n",
    "Directly provide the reordered list of disease names in descending order of likelihood. \\nOutput format:\\nAnswer: <Disease 1>, <Disease 2>, <Disease 3>, ...\n",
    "    '''\n",
    "    input_+=temp+\"\\n\"\n",
    "    result={\n",
    "        \"pid\":pids,\n",
    "        \"hist_diag_code\":hist_diag_code,\n",
    "        \"target_diag_code\":fun1(np.where(target_diag == 1)[0]),\n",
    "        \"instruction\":instruction,\n",
    "        \"input\":input_\n",
    "        \n",
    "    }\n",
    "\n",
    "    results.append(result)\n"
   ],
   "id": "f1aedcd910686b71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "def np_encoder(obj):\n",
    "    if isinstance(obj, (np.integer, np.floating, np.bool_)):\n",
    "        return obj.item()          # 转成 Python int/float/bool\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()        # 转成原生 list\n",
    "    return str(obj)                # 兜底（可选）\n",
    "\n",
    "with open(f\"cra_prompt_m3/m3_cra_r2.json\", \"w\",\n",
    "          encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False,default=np_encoder, indent=2)"
   ],
   "id": "7b718bffb0d1ba21",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
